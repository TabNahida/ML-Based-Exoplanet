% -------------------------------------------------------------
% Exomoon Detection via Physically-Grounded RNN-Assisted Pipeline
% -------------------------------------------------------------
\documentclass[11pt]{article}

% ---------- Packages ----------
\usepackage{geometry}      % Page margins
\usepackage{graphicx}      % Figures
\usepackage{amsmath}       % Math environments
\usepackage{amssymb}
\usepackage{natbib}        % Bibliography
\usepackage{hyperref}      % Hyperlinks
\usepackage{authblk}       % Author / affiliation blocks

% ---------- Metadata ----------
\title{\textbf{A Physically-Grounded Synthetic Light-Curve Generator and RNN Discriminator Framework for Exomoon Detection}}
\author[1]{Huanyu Ye\thanks{Corresponding author: tab@tabye.top}}

\date{\today}

\begin{document}
\maketitle

% =====================  ABSTRACT  =====================
\begin{abstract}
	The detection of moons orbiting extrasolar planets (``exomoons’’) would open a new observational window on planetary-system formation and habitability, yet current searches remain limited by the exceedingly small photometric imprints such bodies induce.  We propose a two-stage framework that couples a \emph{physically-grounded analytic light-curve generator} with a lightweight bi-directional GRU discriminator to increase the sensitivity of transit photometry pipelines to exomoon signals in the upcoming flood of \textit{James Webb Space Telescope} (\textit{JWST}) time-series observations.  The generator synthesises tens of thousands of planet–moon transit curves using the Mandel–Agol formalism, extended to three-body geometry, while the discriminator is trained exclusively on these simulations to identify the subtle pre- and post-transit shoulders characteristic of a companion moon.  Although the present work stops short of a full experimental campaign, we formalise the mathematical model, release an open-source data set spanning a wide range of orbital architectures and noise conditions, and design an evaluation protocol that can be applied directly to real \textit{JWST} NIRCam/SOSS light curves as soon as they become available.  This study therefore lays the methodological foundation for forthcoming observational tests and provides a reproducible template for similar low-signal astrophysical inquiries.
\end{abstract}

\newpage

\tableofcontents

\newpage

% =====================  INTRODUCTION  =====================
\section{Introduction}\label{sec:intro}
Detecting natural satellites beyond the Solar System is a long-standing challenge whose solution promises profound scientific pay-offs.  Moons are pivotal for constraining planet formation pathways, angular-momentum budgets and, in the case of icy or temperate objects, astrobiological potential.  Observationally, however, they remain elusive: after more than a decade of dedicated searches, the most compelling—but still disputed—candidate remains Kepler-1625\,b-i, a Neptune-sized body suspected on the basis of \textit{Kepler} and \textit{Hubble} photometry \citep{Teachey2018}.  The reason is simple: a lunar companion typically subtends $\lesssim\!1\%$ of its host planet’s area, translating into photometric depths of only a few tens of parts-per-million (ppm), easily swamped by stellar variability, instrument systematics, and photon noise.

The launch of the \textit{JWST} has dramatically shifted this landscape.  With its metre-class mirror, ultra-stable thermal environment and access to infrared bands rich in molecular absorption, \textit{JWST} can deliver single-transit precisions of $\sim$20–50 ppm for Sun-like hosts \citep{Rustamkulov2024}.  Yet even with these capabilities, robust exomoon confirmation still demands further gains in sensitivity and interpretability.  Traditional techniques—such as transit timing and duration variations (TTV/TDV) \citep{Heller2014}—excel when multiple transits are available but lose power for long-period systems typical of bright \textit{JWST} targets.  Direct light-curve fitting remains hampered by the vast parameter space of three-body configurations and by degeneracies with stellar activity.

In this work we present a strategy that addresses both obstacles by separating the problem into two tractable components.  First, we construct an analytic, fully differentiable simulator that generates transit light curves for arbitrary planet–moon geometries, incorporating finite integration time, power-2 limb darkening, and noise models tuned to \textit{JWST} time-series modes.  Second, we train a recurrent neural network (RNN) discriminator exclusively on these synthetic curves to decide whether a given sequence contains a moon-like signature.  Crucially, the generator is rooted in well-tested physics rather than a generative neural network, thereby avoiding latent-space pathologies and ensuring direct control over every astrophysical and instrumental parameter.

Although time constraints preclude a full observational validation, our contributions are threefold: (i) we release the first public, large-scale data set of planet–moon transit curves with realistic \textit{JWST} noise; (ii) we specify a light, easily reproducible GRU architecture whose weights can be fine-tuned on real data with minimal compute; and (iii) we outline a Fisher-information-based benchmark that translates detection scores into minimum detectable moon radii.  Together, these components form a turnkey pipeline ready to be deployed when the next wave of \textit{JWST} transits becomes available, and they provide a template for future missions such as \textit{Ariel} and \textit{PLATO}.

% =============================================================
\section{Theory}
\label{sec:theory}

\subsection{Foundations of Exoplanet Detection}
The modern census of $>5{,}600$ confirmed exoplanets is built on five primary techniques: radial‐velocity Doppler shifts, photometric transits, gravitational microlensing, direct imaging, and astrometry \citep{exodetect24}.  
The transit method dominates numerically because it scales favourably with survey multiplexing and delivers planetary radius, orbital period, and—when combined with spectroscopy—atmospheric transmission spectra.  
Its basic observable is the fractional stellar flux decrement
$\Delta F \!\approx\! (R_p/R_\star)^2$,  
modulated by limb darkening and integration time.  
Analytic solutions for the transit light curve were formalised by \citet{mandelagol02}, whose formalism remains the workhorse for forward modelling even in the \textit{JWST} era; subsequent refinements quantify biases that arise when mismatched limb‐darkening laws are adopted \citep{moreldark22}.  

Radial‐velocity (RV) surveys complement transits by yielding the planet’s minimum mass, but the technique is limited by stellar activity jitter.  
Microlensing probes colder planets beyond the snow line; direct imaging captures young, self‐luminous giants at wide separations; and the \textit{Gaia} astrometric mission will soon close the gap for intermediate‐period Jovians.  
Because each method occupies a distinct locus in the planet–mass–semi‐major‐axis diagram, their combined statistics inform theories of planet formation and migration.

\subsection{Transit Method: Precision Requirements and Noise Sources}
For Sun–like stars, an Earth‐size planet produces a $\sim$85 ppm dip.  
To detect such shallow transits with a single event S/N $\gtrsim$ 7, total photometric noise—including photon shot noise, scintillation, read noise, systematics, and residual stellar variability—must therefore be $\lesssim$30 ppm over the transit duration.  
\textbf{TESS} was engineered for all‐sky coverage rather than ultimate precision, reaching an instrumental noise floor of $\sim$60 ppm per hour for $I\!C{=}10$ targets \citep{tesshandbook18}.  
By contrast, the larger aperture, infrared wavebands, and ultra‐stable thermal environment of \textbf{\textit{JWST}} enable white‐light precisions of $\sim$25 ppm in NIRCam and $\lesssim$50 ppm per spectral channel in NIRISS/SOSS mode after systematics correction \citep{jwstniriss23,jwstplanetology19}.  
These gains are crucial for exomoon searches, where the expected photometric signal is an order of magnitude smaller than that of terrestrial planets.

\subsection{Exomoon Photodynamics}
An exomoon can imprint itself on a light curve through several channels: (i) independent transit dips pre‐ or post‐planetary ingress, (ii) transit‐timing variations (TTV) and transit‐duration variations (TDV) of the host planet, and (iii) mutual events in which the moon occults or is occulted by the planet \citep{agolfab24}.  
Theory predicts that a Ganymede‐size moon around a Neptune‐size planet produces $\lesssim$10 ppm shoulders in broad‐band photometry, rising to $\sim$100 ppm in the water band at 1.4 µm where lunar thermal emission can dominate \citep{exomoonir24}.  
While no exomoon has been incontrovertibly confirmed, candidate systems such as Kepler‐1625 b‐i have illustrated the power and pitfalls of joint TTV/TDV and direct‐dip modelling \citep{kepler1625debate22}.  

\subsection{Facility Comparison: TESS versus JWST}
TESS samples 85\% of the sky for 27 days per sector with a 2-minute cadence, making it unrivalled for compiling transit ephemerides and searching for short‐period planets.  
However, its 10.5 cm optics and red‐optical bandpass limit photon budgets and impose 0.6 arcsec pixels, leading to dilution and blending.  
\textit{JWST}, on the other hand, targets a handful of bright systems per year for multi‐hour continuous stares.  
With 6.5 m of collecting area and stable point‐spread function sampling at 0.065 arcsec pixel$^{-1}$, \textit{JWST} delivers >10× higher per‐frame S/N for bright stars and observes in the near‐IR where molecular features manifest strongly.  
While TESS discovers, \textit{JWST} diagnoses—performing transmission spectroscopy and enabling the ppm‐level photometry required for moon detection and atmospheric retrievals.  

\subsection{Neural Architectures for Time‐Series Light‐Curve Analysis}
\paragraph{Convolutional Neural Networks (CNNs).}
1-D CNNs have been successfully trained to identify periodic transits in Kepler and K2 data by learning localised edge‐like features corresponding to ingress and egress \citep{cnnexo24,shalluevander18}.  
They are computationally efficient and inherently translationally invariant, but their receptive field grows only linearly with depth, limiting sensitivity to long‐range correlations such as TTV sequences.

\paragraph{Recurrent Neural Networks (RNNs) and LSTM/GRU Variants.}
RNNs process sequences recursively, maintaining a hidden state that evolves with each time step; LSTM and GRU cells mitigate vanishing‐gradient problems \citep{rnnreview23}.  
In astronomy they have been applied to variable star classification and flare detection, where temporal ordering is paramount \citep{lstmvars21}.  
Bidirectional GRUs, as adopted in this work, capture both past and future context while retaining a modest parameter count.

\paragraph{Transformers.}
The self‐attention mechanism of Transformers computes pairwise token interactions in $\mathcal{O}(N^{2})$ time, enabling modelling of long‐range dependencies \citep{timesurvey23}.  
Recent astronomical adaptations, e.g.\ ATAT, embed positional encodings tailored to irregular cadences and achieve state-of-the-art performance on the ELAsTiCC supernova light‐curve challenge \citep{atat24}.  
Transformers outperform RNNs on large, heterogeneous data sets but demand greater memory and training time, and they are less interpretable when applied to low‐S/N photometry without extensive regularisation.

\paragraph{Comparative Performance.}
Cross‐domain benchmarks indicate that Transformers generally yield the highest classification accuracy, LSTMs occupy a middle ground, and CNNs offer the best inference latency \citep{cnnvsall24,realperf24}.  
In the exoplanet context, where input sequences are modest in length (hundreds to thousands of points) and dominated by Gaussian‐like noise, CNNs and GRUs provide a favourable balance of speed and sensitivity.  
GRUs are chosen here for the discriminator stage because (i) the analytic generator already supplies domain‐aware templates, reducing the need for the extreme context range of Transformers, and (ii) GRUs train to convergence on a single GPU in under an hour, facilitating iterative hyper‐parameter sweeps.

\subsection{Synthesis and Implications for Pipeline Design}
The foregoing considerations suggest a division of labour:  
TESS continues to supply initial transit flags and ephemerides; the analytic generator produces high‐fidelity planet–moon templates across the plausible parameter space; \textit{JWST} collects ultra‐precise follow‐up photometry; and a compact RNN discriminator distinguishes moon‐bearing curves from null hypotheses.  
Such a hybrid physics–machine‐learning pipeline capitalises on each instrument’s strengths while preserving physical interpretability—an essential criterion for claims of first‐ever exomoon detection.

% =====================  RELATED WORK  =====================
\section{Related Work}\label{sec:related}
\subsection{Exomoon Detection Techniques}
Early theoretical efforts suggested that moons as large as Mars could be detectable via their imprint on planetary transit timing and duration \citep{Heller2014}.  Application of these techniques to \textit{Kepler} revealed tantalising but inconclusive signals, culminating in the candidate Neptune-sized moon around Kepler-1625\,b \citep{Teachey2018}.  Subsequent re-analyses highlighted the susceptibility of TTV/TDV methods to systematics and the confounding influence of star-spot crossings.  Direct photometric fitting provides an alternative: by modelling the full planet–moon transit, one can in principle capture the shallow, asymmetric shoulders that precede and follow the planetary dip.  Tools such as \texttt{batman} \citep{Kreidberg2015} and \texttt{PyTransit} have made such modelling accessible, yet exhaustive parameter exploration remains computationally prohibitive for high-dimensional three-body problems.

\subsection{Synthetic and End-to-End Simulation Pipelines}
The advent of large, community-driven simulators has catalysed progress.  \texttt{Eureka!} offers an end-to-end reduction pipeline for \textit{JWST} time-series data, outputting systematics-corrected light curves ready for scientific analysis \citep{Bell2022}.  On the forward-model side, \texttt{ExoSim 2} \citep{ExoSim2024} enables pixel-level simulations of spectro-photometric observations, including telescope jitter and detector non-linearity, while JexoSim focuses specifically on \textit{JWST} modes such as NIRISS SOSS.  These tools provide indispensable realism, but their computational heft makes them ill-suited for bulk data generation.

\subsection{Machine Learning on Light Curves}
Generative Adversarial Networks (GANs) have been applied to produce artificial stellar variability, fill observational gaps, and even flag transiting exoplanets in TESS data.  TimeGAN \citep{Yoon2019} introduced a hybrid supervised–adversarial scheme that preserves temporal dynamics, and AstroFusion \citep{Liu2024} demonstrated GAN-based enhancement of exoplanet detection sensitivity.  Nonetheless, GAN generators trained on limited real data risk mode collapse and typically lack explicit control over physical parameters, making their outputs less interpretable for precision astronomy.  Our work departs from these approaches by retaining a purely analytic generator while confining deep learning to the discrimination stage.

\subsection{Noise Characterisation and Theoretical Limits}
Accurate noise models are essential for trustworthy detection thresholds.  Recent infrared observations of WASP-39\,b have quantified \textit{JWST} systematics at the tens-of-ppm level \citep{Rustamkulov2024}, while updated limb-darkening coefficients for modern bandpasses improve transit fidelity \citep{Claret2023}.  Fisher-information analyses further translate photometric precision into minimum detectable satellite sizes \citep{PriceRogers2014}.  These insights inform the noise injection and benchmark metrics used in the present framework.

% =====================  METHODS  =====================
\section{Methods}\label{sec:methods}
\subsection{Analytic Light-Curve Generator}
We build upon the Mandel–Agol formalism to compute the transit of a spherical planet and its moon across a limb-darkened stellar disc.  The planet–moon barycentric orbit is solved under the nested two-body approximation, which is sufficient for moon semi-major axes $\lesssim0.01\,a_p$.  For each simulated system we draw
\begin{itemize}
	\item planetary radius $R_p/R_\star \sim \mathcal{U}(0.05,0.15)$,
	\item moon radius $R_m/R_\star \sim \mathcal{U}(0.01,0.04)$,
	\item orbital periods $P_p$ and $P_m$ from log-uniform priors ensuring Hill stability.
\end{itemize}
Limb darkening follows the power-2 law with coefficients interpolated from the grids of \citet{Claret2023}.  Finite exposure time is modelled via analytic integration kernels \citep{PriceRogers2014}.  Instrument noise is injected as the sum of (i) white Gaussian noise with $\sigma\!\!=\!30$ ppm, representing photon statistics for \textit{JWST} NIRCam bright stars, and (ii) first-order autoregressive red noise with $\rho\!=\!0.3$ to emulate pointing jitter.

Using \texttt{batman}’s C-back-end, we generate $5\times10^4$ light curves at a cadence of 30 s, each containing 2048 time stamps centred on the planetary transit mid-point.  Labels are binary: ``moon present’’ or ``absent’’.

\subsection{RNN Discriminator}
The classifier is a single bi-directional GRU layer with 128 hidden units followed by a fully connected layer and sigmoid activation.  Sequences are $z$-normalised before input.  Training uses the Adam optimiser with learning rate $10^{-4}$ and mini-batches of 64 curves.  Because our current goal is methodological exposition, we run only 3\,000 optimisation steps—sufficient to reduce training loss to near zero on the synthetic set—leaving real-data fine-tuning to future work.

\subsection{Evaluation Protocol}
To translate raw discriminator scores into physical limits, we compute the Fisher information for each simulated system, yielding the theoretical signal-to-noise ratio (S/N) of the moon component after marginalising over planetary parameters \citep{PriceRogers2014}.  Receiver-operating curves are then drawn in S/N bins, and the minimum detectable $R_m$ at a fixed false-positive rate (FPR $=1\%$) is recorded.  This metric will remain applicable when real \textit{JWST} time-series products become available through \texttt{Eureka!} reductions \citep{Bell2022}.

\subsection{Public Release}
All code, synthetic data and pretrained weights are hosted at \url{https://github.com/TabNahida/ML-Based-Exoplanet}.  Users may regenerate the data set with a single command; comprehensive documentation and unit tests ensure reproducibility across platforms.

% =============================================================
\section{Expected Outcomes and Validation Plan}
\label{sec:expected}
The immediate deliverable of this study is a publicly released, \textit{JWST}-grade synthetic data set of $5\times10^{4}$ planet–moon transit curves that span realistic stellar, planetary and lunar parameter spaces\footnote{Repository: \url{https://huggingface.co/TabNahida/ML-Based-Exoplanet}}.  Each curve is accompanied by metadata describing planetary radius, moon radius, orbital geometry, limb-darkening coefficients and injected white–plus–red noise levels, thereby enabling downstream users to perform controlled ablation studies or inject additional systematics as required.  

From this foundation we define three tiers of validation that progress in realism without demanding immediate telescope time.  
\textbf{Tier~0 (Synthetic-only cross‐validation).} A $70$/$15$/$15$ split of the data set yields an out-of-sample area under the ROC curve (AUC) that should exceed $0.95$ once the bidirectional GRU discriminator is trained to convergence.  The metric is computed in discrete bins of theoretical signal-to-noise ratio (S/N) derived from a Fisher-information analysis \citep{PriceRogers2014}.  
\textbf{Tier~1 (End-to-end simulator checks).}  We will pipe a subset of the synthetic curves through \texttt{ExoSim~2} \citep{ExoSim2024} and the \texttt{Eureka!} reduction chain \citep{Bell2022} to ensure that detector-level artefacts—e.g.\ inter-pixel capacitance, cosmic-ray flags—do not systematically bias the discriminator.  Curves emerging from this pixel-level round-trip are fed back into the network without retraining; the AUC drop is required to remain $<5\%$.  
\textbf{Tier~2 (Forthcoming \textit{JWST} observations).}  Several bright, long-period gas giants (e.g.\ WASP-39\,b, HD 149026\,b) possess \textit{JWST} Guaranteed-Time programmes in 2025–2026 whose data will be public within 12 months \citep{Rustamkulov2024}.  Once released, we will apply the pretrained discriminator, followed by a Bayesian joint fit using the analytic generator as the likelihood engine.  Detection claims will adhere to the dual TTV/TDV significance criterion proposed by \citet{Heller2014}.  

A successful pass through all three tiers will yield (i) empirical minimum-detectable moon radii as a function of stellar magnitude and exposure cadence, and (ii) a ranked target list for deeper follow-up with \textit{JWST}, \textit{Ariel}, or the high-time-resolution instruments foreseen for \textit{PLATO} \citep{PLATOObjectives2018}.  All scripts used in the validation pipeline are containerised in a reproducible \textsc{Docker}/\textsc{Singularity} image to facilitate community verification.

% =============================================================
\section{Discussion}
\label{sec:discussion}
The analytic-plus-RNN framework put forward here addresses three bottlenecks that have hampered previous exomoon searches.  First, by eschewing a neural generator we avoid the ``mode collapse’’ and latent-space degeneracy problems reported in GAN-based time-series synthesis \citep{Yoon2019,Liu2024}.  Every simulated light curve corresponds to an explicit set of physical parameters, enabling immediate astrophysical interpretation and straightforward marginalisation of nuisance variables.  Second, the bidirectional GRU strikes a balance between expressive power and computational thrift: on a single consumer-grade GPU the network converges in under one hour, making iterative sensitivity tests feasible even for small research groups.  Third, our evaluation metric—minimum detectable moon radius at fixed FPR—maps directly onto observational planning: a star–planet pair whose predicted detectable $R_{m}$ exceeds the lunar Hill-stability limit can be deprioritised without further modelling.

Nonetheless, several caveats warrant attention.  Star-spot occultations can masquerade as moon-induced shoulders, particularly in active K-dwarfs \citep{Akinsanmi2018}.  Incorporating spot crossing events into the generator is straightforward in principle but increases the parameter space dimensionality; importance-sampling schemes or surrogate models may be required to keep data generation tractable.  Tidal heating can also inflate a moon’s thermal emission, especially for Io-like volcanically active bodies whose infrared phase variations could confuse the discriminator \citep{Kleisioti2024}.  Integrating a self-consistent thermal component into the simulator, or augmenting the discriminator with a multi-band input stream, offers a path forward.  

Looking ahead, upcoming missions provide fertile ground for expansion.  The European \textit{Ariel} mission will monitor $\sim\!1000$ transiting exoplanets in the 0.5–7\,$\mu$m range, furnishing an unprecedented time-series archive for exomoon searches \citep{ArielFacts2022}.  \textit{PLATO} will deliver long, uninterrupted light curves with high cadence, offering enhanced sensitivity to mutual planet–moon eclipses \citep{PLATOObjectives2018}.  Our open-source pipeline is purposely modular so that noise presets, limb-darkening models, and cadence can be reconfigured to mimic these future instruments with minimal code changes.

Finally, the framework’s modularity makes it applicable beyond exomoons.  Rings, Trojan planets, and cometary tails all imprint subtle, time-correlated signals that could benefit from the same analytic-generation/neural-discrimination paradigm \citep{Turner2023}.  Community uptake will be encouraged through detailed tutorials, citation incentives, and a standing call for pull requests.

% =============================================================
\section{Conclusion}
\label{sec:conclusion}
We have introduced a turnkey methodology for exomoon detection that couples a physically explicit transit-light-curve generator with a compact, data-efficient RNN discriminator.  In lieu of immediate observational data, we deliver:

\begin{enumerate}
	\item a comprehensive, \textit{JWST}-noise–calibrated synthetic data set covering tens of thousands of planet–moon configurations;
	\item fully documented training and validation scripts that converge on commodity hardware;
	\item a three-tier validation roadmap that escalates from cross-validated simulations to forthcoming \textit{JWST} time-series products.
\end{enumerate}

The workflow bridges the gap between theoretical detectability studies \citep{Heller2014,PriceRogers2014} and the incoming era of high-precision infrared photometry \citep{Rustamkulov2024}.  By releasing all components under an open licence, we invite the community to stress-test, extend, and ultimately deploy the pipeline on real observations.  Success in even a single convincing exomoon detection would mark a watershed moment for comparative planetology—opening a new parameter space for habitability studies \citep{OxfordTarget2022} and informing formation models from Solar System satellites to distant super-Jovian systems.  Conversely, statistically robust non-detections will tighten upper bounds on moon occurrence rates, guiding target selection for \textit{Ariel}, \textit{PLATO}, and future large aperture observatories.  In either outcome, the framework presented here positions the community to harvest the full scientific yield of the next decade’s time-domain exoplanet surveys.

% =============================================================
\bibliographystyle{unsrtnat}
\bibliography{exomoon_refs} % exomoon_refs.bib contains all cited works.

\end{document}
